Metadata-Version: 2.1
Name: omniduct
Version: 1.1.19
Summary: A toolkit providing a uniform interface for connecting to and extracting data from a wide variety of (potentially remote) data stores (including HDFS, Hive, Presto, MySQL, etc).
Home-page: https://github.com/airbnb/omniduct
Author: Matthew Wardrop, Dan Frank
Author-email: mpwardrop@gmail.com, danfrankj@gmail.com
License: MIT
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Environment :: Console
Classifier: Environment :: Web Environment
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: future
Requires-Dist: six
Requires-Dist: interface-meta (<2,>=1.1.0)
Requires-Dist: pyyaml
Requires-Dist: decorator
Requires-Dist: progressbar2 (>=3.30.0)
Requires-Dist: wrapt
Requires-Dist: jinja2
Requires-Dist: pandas (>=0.17.1)
Requires-Dist: sqlparse
Requires-Dist: sqlalchemy
Requires-Dist: python-dateutil
Requires-Dist: lazy-object-proxy
Provides-Extra: all
Requires-Dist: pydruid (>=0.4.0) ; extra == 'all'
Requires-Dist: pyhive[hive] (>=0.4) ; extra == 'all'
Requires-Dist: thrift (>=0.10.0) ; extra == 'all'
Requires-Dist: pyhive[presto] (>=0.4) ; extra == 'all'
Requires-Dist: pyspark ; extra == 'all'
Requires-Dist: snowflake-sqlalchemy ; extra == 'all'
Requires-Dist: pyexasol ; extra == 'all'
Requires-Dist: pywebhdfs ; extra == 'all'
Requires-Dist: requests ; extra == 'all'
Requires-Dist: boto3 ; extra == 'all'
Requires-Dist: pexpect ; extra == 'all'
Requires-Dist: paramiko ; extra == 'all'
Requires-Dist: sphinx ; extra == 'all'
Requires-Dist: sphinx-autobuild ; extra == 'all'
Requires-Dist: sphinx-rtd-theme ; extra == 'all'
Requires-Dist: nose ; extra == 'all'
Requires-Dist: mock ; extra == 'all'
Requires-Dist: pyfakefs ; extra == 'all'
Requires-Dist: coverage ; extra == 'all'
Requires-Dist: flake8 ; extra == 'all'
Provides-Extra: docs
Requires-Dist: sphinx ; extra == 'docs'
Requires-Dist: sphinx-autobuild ; extra == 'docs'
Requires-Dist: sphinx-rtd-theme ; extra == 'docs'
Provides-Extra: druid
Requires-Dist: pydruid (>=0.4.0) ; extra == 'druid'
Provides-Extra: exasol
Requires-Dist: pyexasol ; extra == 'exasol'
Provides-Extra: hiveserver2
Requires-Dist: pyhive[hive] (>=0.4) ; extra == 'hiveserver2'
Requires-Dist: thrift (>=0.10.0) ; extra == 'hiveserver2'
Provides-Extra: presto
Requires-Dist: pyhive[presto] (>=0.4) ; extra == 'presto'
Provides-Extra: pyspark
Requires-Dist: pyspark ; extra == 'pyspark'
Provides-Extra: rest
Requires-Dist: requests ; extra == 'rest'
Provides-Extra: s3
Requires-Dist: boto3 ; extra == 's3'
Provides-Extra: snowflake
Requires-Dist: snowflake-sqlalchemy ; extra == 'snowflake'
Provides-Extra: ssh
Requires-Dist: pexpect ; extra == 'ssh'
Provides-Extra: ssh_paramiko
Requires-Dist: paramiko ; extra == 'ssh_paramiko'
Requires-Dist: pexpect ; extra == 'ssh_paramiko'
Provides-Extra: test
Requires-Dist: nose ; extra == 'test'
Requires-Dist: mock ; extra == 'test'
Requires-Dist: pyfakefs ; extra == 'test'
Requires-Dist: coverage ; extra == 'test'
Requires-Dist: flake8 ; extra == 'test'
Provides-Extra: webhdfs
Requires-Dist: pywebhdfs ; extra == 'webhdfs'
Requires-Dist: requests ; extra == 'webhdfs'

`omniduct` provides uniform interfaces for connecting to and extracting data from a wide variety of (potentially remote) data stores (including HDFS, Hive, Presto, MySQL, etc).

- **Documentation:** http://omniduct.readthedocs.io
- **Source:** https://github.com/airbnb/omniduct
- **Bug reports:** https://github.com/airbnb/omniduct/issues

It provides:

- A generic plugin-based programmatic API to access data in a consistent manner across different services (see [supported protocols](http://omniduct.readthedocs.io/en/latest/protocols.html)).
- A framework for lazily connecting to data sources and maintaining these connections during the entire lifetime of the relevant Python session.
- Automatic port forwarding of remote services over SSH where connections cannot be made directly.
- Convenient IPython magic functions for interfacing with data providers from within IPython and Jupyter Notebook sessions.
- Utility classes and methods to assist in maintaining registries of useful services.

**Note:** Omniduct 1.1.x is the last version series to support Python 2. Going
forward it will support Python 3.6+.


