import pickle
import torch
import typing as tp

from gensim.models.keyedvectors import FastTextKeyedVectors
from TakeSentimentAnalysis import utils, vocab, data, model

DICT_SENTENCES = tp.Optional[tp.List[tp.Dict[str, tp.Any]]]
DATA_TYPE = tp.Union[data.ModelIterableDatasetCSV, data.ModelBatchDataset]


def create_input_vocab(input_sentence: list) -> vocab.Vocabulary:
    """Create vocabulary based on a single sentence

    Parameters
    ----------
    input_sentence: list
        List with the tokens of the sentence to generate the vocabulary.

    Return
    ------
    vocab.Vocabulary
        Vocabulary generated by the input sentence.
    """
    vocabulary = vocab.Vocabulary()
    vocabulary.add('<pad>')
    vocabulary.add("<unk>")
    vocab.populate_vocab(input_sentence, vocabulary)
    return vocabulary


class SentimentPredict:
    """
    Wraps all predict functions.
    """

    def __init__(self, trained_model: model.LSTM, label_path: str,
                 embedding: FastTextKeyedVectors, save_dir: str = None,
                 encoding: str = None, separator: str = None):
        """
        Parameters
        ----------
        trained_model: model.LSTM
            Model to be used in the predictions
        label_path: str
            Path to input file that contains the label vocab
        embedding: FastTextKeyedVectors
            Embedding model to be use.
        save_dir: str
            Directory to save predict.
        encoding: str
            Input file encoding.
        separator: str
            Input file column separator.
        """
        self.model = trained_model
        self.label_path = label_path
        self.label_vocab = self.read_label_vocab()
        self.save_dir = save_dir
        self.encoding = encoding
        self.separator = separator
        self.embedding = embedding
        self.model.train(False)
        self.model.device = 'cpu'

    def read_label_vocab(self) -> vocab.Vocabulary:
        """Read label vocabulary

        Return
        ------
        vocab.Vocabulary
            Vocabulary of the labels to be predict.
        """
        with open(self.label_path, 'rb') as file:
            label_vocab = pickle.load(file)
        return label_vocab

    def update_embedding_values(self, input_vocab: vocab.Vocabulary) -> None:
        """Update embedding values based on a vocabulary

        Parameters
        ----------
        input_vocab: vocab.Vocabulary
            Vocabulary to be used in the embedding layer in model.
        """
        self.model.reset_embedding(len(input_vocab))
        embedding_value = self.embedding[input_vocab.i2f.values()]
        self.model.embeddings[0].weight.data = torch.from_numpy(
            embedding_value)
        self.model.embeddings[0].weight.requires_grad = False

    def predict_line(self, line: str,
                     use_pre_processing: bool = True) -> tp.Tuple[str, str]:
        """Predict the model label for a single sentence

        Parameters
        ----------
        line: str
            Sentence to predict the label.
        use_pre_processing: bool
            Whether to pre process sentence.

        Return
        ------
        tp.Tuple[str, str]
            Processed sentence and predict label.
        """
        if use_pre_processing:
            line = utils.pre_process(line)
        if len(line) == 0:
            return '', ''
        split_line = line.split()
        input_vocab = create_input_vocab([split_line])
        self.update_embedding_values(input_vocab)
        indexed_line = utils.get_words_id(split_line, input_vocab)
        with torch.no_grad():
            line_len = torch.LongTensor([len(split_line)])
            indexed_line = torch.cat(
                [torch.LongTensor([indexed_line]).unsqueeze(0)])
            predict = self.model.predict(indexed_line, line_len)
        return line, self.label_vocab[predict.data.tolist()[0]]

    def predict_batch_file(self, filepath: str, sentence_column: str,
                           pad_string: str, unk_string: str, batch_size: int,
                           shuffle: bool, use_pre_processing: bool) -> DICT_SENTENCES:
        """Predict the model label for a batch of sentences
        Parameters
        ----------
        filepath: str
            Path to the input file containing the sentences to be predicted.
        sentence_column: str
            String with the name of the column of sentences
        pad_string: str
            String that represents pad.
        unk_string: str
            String that represents unknown.
        batch_size
            Mini-batch size to predict.
        shuffle: bool
            Whether to shuffle the dataset.
        use_pre_processing: bool
            Whether to pre process input data.

        Return
        ------
        DICT_SENTENCES
            [Optional] A list of dictionaries with the id of the sentence, the
            sentence and the predict label.
        """

        input_vocab = vocab.create_vocabulary(
            input_path=filepath,
            column_name=sentence_column,
            pad_string=pad_string,
            unk_string=unk_string,
            encoding=self.encoding,
            separator=self.separator,
            use_pre_processing=use_pre_processing)

        dataset = data.ModelIterableDatasetCSV(
            path=filepath,
            label_column=None,
            encoding=self.encoding,
            separator=self.separator,
            use_pre_processing=use_pre_processing)

        utils.create_save_file(self.save_dir)

        self.predict_batch(dataset, input_vocab, False, pad_string, unk_string,
                           batch_size, shuffle)

    def predict_batch_sentences(self, pad_string: str, unk_string: str,
                                batch_size: int,
                                shuffle: bool, use_pre_processing: bool,
                                sentences: DICT_SENTENCES = None) -> DICT_SENTENCES:
        """Predict the model label for a batch of sentences
        Parameters
        ----------
        pad_string: str
            String that represents pad.
        unk_string: str
            String that represents unknown.
        batch_size
            Mini-batch size to predict.
        shuffle: bool
            Whether to shuffle the dataset.
        use_pre_processing: bool
            Whether to pre process input data.
        sentences: DICT_SENTENCES
            [Optional] A list of dictionaries with the id of the sentence and
            the sentence. Default: None

        Return
        ------
        DICT_SENTENCES
            [Optional] A list of dictionaries with the id of the sentence, the
            sentence and the predict label.
        """

        input_vocab = vocab.create_vocabulary(
            input_path="",
            column_name="",
            pad_string=pad_string,
            unk_string=unk_string,
            encoding=self.encoding,
            separator=self.separator,
            use_pre_processing=use_pre_processing,
            sentences=sentences)

        predictions = []

        dataset = data.ModelBatchDataset(
            use_pre_processing=use_pre_processing,
            sentences=sentences)

        predictions = self.predict_batch(dataset, input_vocab, True,
                                         pad_string,
                                         unk_string, batch_size, shuffle,
                                         predictions)

        return predictions

    def predict_batch(self, dataset: DATA_TYPE, input_vocab: vocab.Vocabulary,
                      use_index: bool, pad_string: str, unk_string: str,
                      batch_size: int, shuffle: bool,
                      predictions: tp.Optional[DICT_SENTENCES] = None) -> \
            tp.Optional[DICT_SENTENCES]:
        """Predict the model label for a batch of sentences
        Parameters
        ----------
        dataset: DATA_TYPE

        input_vocab: vocab.Vocabulary

        use_index: bool

        pad_string: str
            String that represents pad.
        unk_string: str
            String that represents unknown.
        batch_size
            Mini-batch size to predict.
        shuffle: bool
            Whether to shuffle the dataset.
        predictions: tp.Optional[DICT_SENTENCES]

        Return
        ------
        DICT_SENTENCES
            [Optional] A list of dictionaries with the id of the sentence, the
            sentence and the predict label.
        """

        data_load = data.ModelDataLoader(
            dataset=dataset,
            vocabs=[input_vocab],
            pad_string=pad_string,
            unk_string=unk_string,
            batch_size=batch_size,
            shuffle=shuffle,
            use_index=use_index,
            is_train=False)

        self.update_embedding_values(input_vocab)

        for iteration_idx, (batch, lens, _, index) in enumerate(
                data_load):
            with torch.no_grad():
                batch_sentences, batch_index, batch_lens = utils.prepare_batch(
                    batch, None, lens, index)
                preds = self.model.predict(batch_sentences, batch_lens)

            preds_list = preds.data.tolist()
            batch_list = batch_sentences.data.tolist()[0]

            unindex_label = [self.label_vocab[label] for label in preds_list]

            unindex_sequence = utils.get_sequence_words_by_id(batch_list,
                                                              batch_lens,
                                                              input_vocab)

            if predictions is not None:
                index_all = batch_index.data.tolist()
                predictions += [{'id': ind,
                                 'processed_sentence': ' '.join(sentence),
                                 'sentiment': pred}
                                for ind, sentence, pred in zip(index_all,
                                                               unindex_sequence,
                                                               unindex_label)]
            else:
                utils.save_predict(self.save_dir, unindex_sequence,
                                   unindex_label)

        return predictions
