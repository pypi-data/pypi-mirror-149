#######################################################################
#                           Metadata files                            #
#######################################################################
metadata:
  runlib2samp_file: "rawdata/rl2s.tsv"
  sample_meta_file: "rawdata/samples.tsv"
  setfile_glob: "rawdata/setfiles/*.txt"


#######################################################################
#                           Raw Fastq Data                            #
#######################################################################
# Paths to raw data. These should be consistent across all samples. Samples
# must have either an R1 and R2, or an interleaved (il) fastq file per run and
# library. Having both is an error. If you somehow end up with both, combine
# the R1 & R2 files and append them to the interleaved, then remove the
# original R1/R2 files.
raw_paths:
  r1_path: "rawdata/reads/{run}/{lib}_R1.fastq.gz"
  r2_path: "rawdata/reads/{run}/{lib}_R2.fastq.gz"
  il_path: "rawdata/reads/{run}/{lib}_il.fastq.gz"


#######################################################################
#                          Reference Genomes                          #
#######################################################################
refs:
  ancestral:
    # For each reference we need a gtf and a genome fasta file.
    # The genome fasta file must be faidx-indexed **BEFORE** the pipeline is
    # run. Other indexes (e.g. bwa, ngm) are run as part of the pipeline, but
    # the pipeline code needs to know the lengths of chromosomes before it
    # runs, so for now you must `samtools faidx` each fasta file you put here
    # manually ahead of running snakemake.
    fasta: "rawdata/reference/genome.fa"
    gtf: "rawdata/reference/genome.gtf"
    # For snpEff, we need two other bits of metadata. The organism name (which
    # is used in snpEff reports), and any additional lines of config in the
    # snpEff.config file for this reference. This is where one should specificy
    # custom translation codes etc.  See the snpEff documentation.
    organism: Lambda Phage
    snpeff_extra_config: ""


#######################################################################
#                               Read QC                               #
#######################################################################
qc:
  _DEFAULT_:
    # _DEFAULT_ describes the settings to use for all runs except those
    # specifically named below.
    adapter_file: "rawdata/adapters.txt"
    minqual: 20
    qualenc: 33
    maxqualval: 45
  # Example special run
  # some_run:
  #   # One can specify a different set of oligos like so for any runs run on a
  #   # different platform. NB, this must be done per-run, not per library.
  #   minqual: 25



#######################################################################
#                               Kraken                                #
#######################################################################
kraken:

  # A mapping of db_name -> download URL. DBs will be automatically downloaded.
  dburls:
    Viral: "https://genome-idx.s3.amazonaws.com/kraken/k2_viral_20201202.tar.gz"
    # typically the far more useful:
    #PlusPFP: "https://genome-idx.s3.amazonaws.com/kraken/k2_pluspfp_20210127.tar.gz"

  samplesets:
    all:
      - Viral


#######################################################################
#                               Multiqc                               #
#######################################################################
multiqc:
  # A mapping of sampleset: multiqc stage reports. Stages are:
  # - rawreads
  # - samplereads
  # - alignment
  all:
    - rawreads
    - samplereads
    - bamstats
    - kraken


#######################################################################
#                       Alignment to Reference                        #
#######################################################################
align:
  aligners:
    - bwa
    - ngm
  refs:
    - ancestral
  samplesets:
    - all
  ngm: # tool specific settings
    sensitivity: 0.5
  abra2:
    java_args: '-Xmx16G'
    extra_args:
      # one can supply extra arguments (e.g. --targets) to abra, per reference genome
      ancestral: ""


#######################################################################
#                   Non-gatk-based Variant Calling                    #
#######################################################################
varcall:
  # Should bcftools concat allow overlaps while merging region files (generally
  # false, occasionally needed with freebayes)
  merge_allow_overlaps: False
  
  # Per-aligner minimum MAPQ thresholds for using a read.
  minmapq:
    bwa: 30  # bwa scores approximately follow a PHRED scale (-10*log10(p))
    ngm: 10  # NGM scores are bonkers, and don't follow a particularly clear scale. in practice ~10 seems appropriate


  # Minimum base quality to count *base* in pileup
  minbq: 15 
  
  # Chunk size for parallisation across genome. Per variant caller as they take
  # have different runtime and memory requirements, and all need to fit in
  # ~12hours on a single job.
  chunksize:
    mpileup:   2000000
    freebayes:   50000
    gatk-hc: 100000000

  # The main per-sample set configuration. Here we select which variant
  # callers, aligners, and reference genomes get used, and set some parameters
  # specific to each sample set.
  samplesets:
    all:
      theta_prior: 0.001
      aligners:
        - ngm
        - bwa
        - bwa_abra2
      callers:
        - mpileup
        - freebayes
      refs:
        - ancestral
      filters:
        - default
      snpeff: True


  # Filters. These are series of command line arguments to pass to bcftools
  # view. These filters apply while multiallelic variants have been decomposed
  # into multiple overlapping variant calls. This allows e.g. allele frequency
  # filters to be performed on a per-allele basis.
  filters:
    default: >
      -i 'QUAL >= 10 &&
          ALT != "." &&
          INFO/DP >= 5 &&
          INFO/AN >= 3'


#######################################################################
#                        Cluster Configuration                        #
#######################################################################
# Here one can set the resources each job will request from the cluster. 
cluster_resources:
  DEBUG: false
  # Must jobs requiring intenet be run on the head node? set to True for
  # clusters where no nodes have internet access, otherwise use a job to some
  # queue that has internet (via the jobsubmit script).
  internet_only_localrules: True
  defaults:
    mem_gb: 2
    time_min: 60
  max_values:
    mem_gb: 192
    time_min: 2880 # 48h
  rules:
    # A mapping of rule_name: resource overrides, e.g.
    qcreads:
      mem_gb: 192
      time_min: 2880 # 48h
